{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9637274,"sourceType":"datasetVersion","datasetId":5884310}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install  ml_collections","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T19:48:31.395024Z","iopub.execute_input":"2024-11-14T19:48:31.395381Z","iopub.status.idle":"2024-11-14T19:48:44.645274Z","shell.execute_reply.started":"2024-11-14T19:48:31.395346Z","shell.execute_reply":"2024-11-14T19:48:44.644132Z"}},"outputs":[{"name":"stdout","text":"Collecting ml_collections\n  Downloading ml_collections-1.0.0-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from ml_collections) (1.4.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from ml_collections) (1.16.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from ml_collections) (6.0.2)\nDownloading ml_collections-1.0.0-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: ml_collections\nSuccessfully installed ml_collections-1.0.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install apex","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T19:48:44.647375Z","iopub.execute_input":"2024-11-14T19:48:44.647690Z","iopub.status.idle":"2024-11-14T19:49:30.740899Z","shell.execute_reply.started":"2024-11-14T19:48:44.647657Z","shell.execute_reply":"2024-11-14T19:49:30.739835Z"}},"outputs":[{"name":"stdout","text":"Collecting apex\n  Downloading apex-0.9.10dev.tar.gz (36 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting cryptacular (from apex)\n  Downloading cryptacular-1.6.2.tar.gz (75 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.8/75.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting zope.sqlalchemy (from apex)\n  Downloading zope.sqlalchemy-3.1-py3-none-any.whl.metadata (18 kB)\nCollecting velruse>=1.0.3 (from apex)\n  Downloading velruse-1.1.1.tar.gz (709 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.8/709.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting pyramid>1.1.2 (from apex)\n  Downloading pyramid-2.0.2-py3-none-any.whl.metadata (20 kB)\nCollecting pyramid_mailer (from apex)\n  Downloading pyramid_mailer-0.15.1-py2.py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from apex) (2.32.3)\nCollecting wtforms (from apex)\n  Downloading wtforms-3.2.1-py3-none-any.whl.metadata (5.3 kB)\nCollecting wtforms-recaptcha (from apex)\n  Downloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl.metadata (3.1 kB)\nCollecting hupper>=1.5 (from pyramid>1.1.2->apex)\n  Downloading hupper-1.12.1-py3-none-any.whl.metadata (3.7 kB)\nCollecting plaster (from pyramid>1.1.2->apex)\n  Downloading plaster-1.1.2-py2.py3-none-any.whl.metadata (6.4 kB)\nCollecting plaster-pastedeploy (from pyramid>1.1.2->apex)\n  Downloading plaster_pastedeploy-1.0.1-py2.py3-none-any.whl.metadata (8.1 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pyramid>1.1.2->apex) (70.0.0)\nCollecting translationstring>=0.4 (from pyramid>1.1.2->apex)\n  Downloading translationstring-1.4-py2.py3-none-any.whl.metadata (4.1 kB)\nCollecting venusian>=1.0 (from pyramid>1.1.2->apex)\n  Downloading venusian-3.1.0-py3-none-any.whl.metadata (10 kB)\nCollecting webob>=1.8.3 (from pyramid>1.1.2->apex)\n  Downloading WebOb-1.8.9-py2.py3-none-any.whl.metadata (11 kB)\nCollecting zope.deprecation>=3.5.0 (from pyramid>1.1.2->apex)\n  Downloading zope.deprecation-5.0-py3-none-any.whl.metadata (5.1 kB)\nCollecting zope.interface>=3.8.0 (from pyramid>1.1.2->apex)\n  Downloading zope.interface-7.1.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from velruse>=1.0.3->apex) (2.0.0)\nCollecting anykeystore (from velruse>=1.0.3->apex)\n  Downloading anykeystore-0.2.tar.gz (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting python3-openid (from velruse>=1.0.3->apex)\n  Downloading python3_openid-3.2.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting pbkdf2 (from cryptacular->apex)\n  Downloading pbkdf2-1.3.tar.gz (6.4 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting repoze.sendmail>=4.1 (from pyramid_mailer->apex)\n  Downloading repoze.sendmail-4.4.1-py2.py3-none-any.whl.metadata (8.3 kB)\nCollecting transaction (from pyramid_mailer->apex)\n  Downloading transaction-5.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->apex) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->apex) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->apex) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->apex) (2024.8.30)\nRequirement already satisfied: markupsafe in /opt/conda/lib/python3.10/site-packages (from wtforms->apex) (2.1.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from zope.sqlalchemy->apex) (21.3)\nRequirement already satisfied: SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1 in /opt/conda/lib/python3.10/site-packages (from zope.sqlalchemy->apex) (2.0.30)\nRequirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1->zope.sqlalchemy->apex) (4.12.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1->zope.sqlalchemy->apex) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->zope.sqlalchemy->apex) (3.1.2)\nCollecting PasteDeploy>=2.0 (from plaster-pastedeploy->pyramid>1.1.2->apex)\n  Downloading PasteDeploy-3.1.0-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from python3-openid->velruse>=1.0.3->apex) (0.7.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib->velruse>=1.0.3->apex) (3.2.2)\nDownloading pyramid-2.0.2-py3-none-any.whl (247 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyramid_mailer-0.15.1-py2.py3-none-any.whl (19 kB)\nDownloading wtforms-3.2.1-py3-none-any.whl (152 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.5/152.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl (7.5 kB)\nDownloading zope.sqlalchemy-3.1-py3-none-any.whl (23 kB)\nDownloading hupper-1.12.1-py3-none-any.whl (22 kB)\nDownloading repoze.sendmail-4.4.1-py2.py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transaction-5.0-py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading translationstring-1.4-py2.py3-none-any.whl (15 kB)\nDownloading venusian-3.1.0-py3-none-any.whl (13 kB)\nDownloading WebOb-1.8.9-py2.py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.4/115.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading zope.deprecation-5.0-py3-none-any.whl (10 kB)\nDownloading zope.interface-7.1.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (254 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.2/254.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading plaster-1.1.2-py2.py3-none-any.whl (11 kB)\nDownloading plaster_pastedeploy-1.0.1-py2.py3-none-any.whl (7.8 kB)\nDownloading python3_openid-3.2.0-py3-none-any.whl (133 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading PasteDeploy-3.1.0-py3-none-any.whl (16 kB)\nBuilding wheels for collected packages: apex, velruse, cryptacular, anykeystore, pbkdf2\n  Building wheel for apex (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for apex: filename=apex-0.9.10.dev0-py3-none-any.whl size=46442 sha256=48bc1f1d550404523cea495497076f7bdd55628e5b2b4260e7f6e52bc3f58b3d\n  Stored in directory: /root/.cache/pip/wheels/6e/62/59/9b100fce7ebd989603b3b7a4ca259150da72c9e107fcaa2a30\n  Building wheel for velruse (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for velruse: filename=velruse-1.1.1-py3-none-any.whl size=50909 sha256=887882c4a1591d2386903ff4f8e42316554187455b522a28442b17c3598c03a5\n  Stored in directory: /root/.cache/pip/wheels/4a/f9/a4/fc4ea7b935ee9c58b9bc772cabd94f6a8560f35444097d948d\n  Building wheel for cryptacular (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for cryptacular: filename=cryptacular-1.6.2-cp310-cp310-linux_x86_64.whl size=28076 sha256=fe5fb253800105ada3e72aceebb7be2f14f674ffc4a1fd0c1e770fbba1606ac3\n  Stored in directory: /root/.cache/pip/wheels/3f/6e/09/a7fba517f95b2a6a36bd01b6d4f4679fa7259615a493b64b8f\n  Building wheel for anykeystore (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for anykeystore: filename=anykeystore-0.2-py3-none-any.whl size=16813 sha256=419a4b06e2c5446781b5ad7a8fad1d6ca6ec479d293f22fcbc9aac29a6baed77\n  Stored in directory: /root/.cache/pip/wheels/ce/9e/24/35542b7d376b53a6f8426524cc5a3f7998f975037b32d19906\n  Building wheel for pbkdf2 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pbkdf2: filename=pbkdf2-1.3-py3-none-any.whl size=5083 sha256=b1438a772951dfa6ce936973b326a8441b89ad123ea85635d86fcfd33614c2a5\n  Stored in directory: /root/.cache/pip/wheels/f6/7d/8b/4269ff90fda80497ec59f6ff7d1e1596cb697c1dc8e9bbe320\nSuccessfully built apex velruse cryptacular anykeystore pbkdf2\nInstalling collected packages: translationstring, pbkdf2, anykeystore, zope.interface, zope.deprecation, wtforms, webob, venusian, python3-openid, plaster, PasteDeploy, hupper, cryptacular, wtforms-recaptcha, transaction, plaster-pastedeploy, zope.sqlalchemy, repoze.sendmail, pyramid, velruse, pyramid_mailer, apex\nSuccessfully installed PasteDeploy-3.1.0 anykeystore-0.2 apex-0.9.10.dev0 cryptacular-1.6.2 hupper-1.12.1 pbkdf2-1.3 plaster-1.1.2 plaster-pastedeploy-1.0.1 pyramid-2.0.2 pyramid_mailer-0.15.1 python3-openid-3.2.0 repoze.sendmail-4.4.1 transaction-5.0 translationstring-1.4 velruse-1.1.1 venusian-3.1.0 webob-1.8.9 wtforms-3.2.1 wtforms-recaptcha-0.3.2 zope.deprecation-5.0 zope.interface-7.1.1 zope.sqlalchemy-3.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#configs.py\n\nimport ml_collections\n\n\ndef get_testing():\n    \"\"\"Returns a minimal configuration for testing.\"\"\"\n    config = ml_collections.ConfigDict()\n    config.patches = ml_collections.ConfigDict({'size': (16, 16)})\n    config.hidden_size = 1\n    config.transformer = ml_collections.ConfigDict()\n    config.transformer.mlp_dim = 1\n    config.transformer.num_heads = 1\n    config.transformer.num_layers = 1\n    config.transformer.attention_dropout_rate = 0.0\n    config.transformer.dropout_rate = 0.1\n    config.classifier = 'token'\n    config.representation_size = None\n    return config\n\n\ndef get_b16_config():\n    \"\"\"Returns the ViT-B/16 configuration.\"\"\"\n    config = ml_collections.ConfigDict()\n    config.patches = ml_collections.ConfigDict({'size': (16, 16)})\n    config.hidden_size = 768\n    config.transformer = ml_collections.ConfigDict()\n    config.transformer.mlp_dim = 3072\n    config.transformer.num_heads = 12\n    config.transformer.num_layers = 12\n    config.transformer.attention_dropout_rate = 0.0\n    config.transformer.dropout_rate = 0.1\n    config.classifier = 'token'\n    config.representation_size = None\n    return config\n\n\ndef get_r50_b16_config():\n    \"\"\"Returns the Resnet50 + ViT-B/16 configuration.\"\"\"\n    config = get_b16_config()\n    del config.patches.size\n    config.patches.grid = (14, 14)\n    config.resnet = ml_collections.ConfigDict()\n    config.resnet.num_layers = (3, 4, 9)\n    config.resnet.width_factor = 1\n    return config\n\n\ndef get_b32_config():\n    \"\"\"Returns the ViT-B/32 configuration.\"\"\"\n    config = get_b16_config()\n    config.patches.size = (32, 32)\n    return config\n\n\ndef get_l16_config():\n    \"\"\"Returns the ViT-L/16 configuration.\"\"\"\n    config = ml_collections.ConfigDict()\n    config.patches = ml_collections.ConfigDict({'size': (16, 16)})\n    config.hidden_size = 1024\n    config.transformer = ml_collections.ConfigDict()\n    config.transformer.mlp_dim = 4096\n    config.transformer.num_heads = 16\n    config.transformer.num_layers = 24\n    config.transformer.attention_dropout_rate = 0.0\n    config.transformer.dropout_rate = 0.1\n    config.classifier = 'token'\n    config.representation_size = None\n    return config\n\n\ndef get_l32_config():\n    \"\"\"Returns the ViT-L/32 configuration.\"\"\"\n    config = get_l16_config()\n    config.patches.size = (32, 32)\n    return config\n\n\ndef get_h14_config():\n    \"\"\"Returns the ViT-L/16 configuration.\"\"\"\n    config = ml_collections.ConfigDict()\n    config.patches = ml_collections.ConfigDict({'size': (14, 14)})\n    config.hidden_size = 1280\n    config.transformer = ml_collections.ConfigDict()\n    config.transformer.mlp_dim = 5120\n    config.transformer.num_heads = 16\n    config.transformer.num_layers = 32\n    config.transformer.attention_dropout_rate = 0.0\n    config.transformer.dropout_rate = 0.1\n    config.classifier = 'token'\n    config.representation_size = None\n    return config","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-14T19:49:30.742310Z","iopub.execute_input":"2024-11-14T19:49:30.742615Z","iopub.status.idle":"2024-11-14T19:49:30.830170Z","shell.execute_reply.started":"2024-11-14T19:49:30.742582Z","shell.execute_reply":"2024-11-14T19:49:30.829379Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#data_utils.py\n\nimport logging\n\nimport torch\n\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader, RandomSampler, DistributedSampler, SequentialSampler\nlogger = logging.getLogger(__name__)\ndef get_loader(args):\n    if args.local_rank not in [-1, 0]:\n        torch.distributed.barrier()\n\n    transform_train = transforms.Compose([\n        transforms.RandomResizedCrop((args.img_size, args.img_size), scale=(0.05, 1.0)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n    ])\n    transform_test = transforms.Compose([\n        transforms.Resize((args.img_size, args.img_size)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n    ])\n    dataset_path = args.dataset_path\n\n    train_dir = \"/kaggle/input/persian-food-image20mehr/Persian_Food20mehr(80train,20test)/train\"\n    test_dir = \"/kaggle/input/persian-food-image20mehr/Persian_Food20mehr(80train,20test)/test\"\n    train_data = datasets.ImageFolder(train_dir, transform=transform_train)\n    test_data = datasets.ImageFolder(test_dir, transform=transform_test)\n    if args.local_rank == 0:\n        torch.distributed.barrier()\n    train_loader = DataLoader(train_data,\n                              batch_size=args.train_batch_size,\n                              shuffle=True,\n                              num_workers=4,\n                              pin_memory=True)\n    test_loader = DataLoader(test_data,\n                             batch_size=args.eval_batch_size,\n                             num_workers=4,\n                             shuffle=False,\n                             pin_memory=True)\n    return train_loader, test_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T19:49:30.832310Z","iopub.execute_input":"2024-11-14T19:49:30.832621Z","iopub.status.idle":"2024-11-14T19:49:35.347830Z","shell.execute_reply.started":"2024-11-14T19:49:30.832589Z","shell.execute_reply":"2024-11-14T19:49:35.346950Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#data_util.py\n\nimport torch.distributed as dist\n\ndef get_rank():\n    if not dist.is_available():\n        return 0\n    if not dist.is_initialized():\n        return 0\n    return dist.get_rank()\n\ndef get_world_size():\n    if not dist.is_available():\n        return 1\n    if not dist.is_initialized():\n        return 1\n    return dist.get_world_size()\n\ndef is_main_process():\n    return get_rank() == 0\n\ndef format_step(step):\n    if isinstance(step, str):\n        return step\n    s = \"\"\n    if len(step) > 0:\n        s += \"Training Epoch: {} \".format(step[0])\n    if len(step) > 1:\n        s += \"Training Iteration: {} \".format(step[1])\n    if len(step) > 2:\n        s += \"Validation Iteration: {} \".format(step[2])\n    return s","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T19:49:35.349059Z","iopub.execute_input":"2024-11-14T19:49:35.349564Z","iopub.status.idle":"2024-11-14T19:49:35.358216Z","shell.execute_reply.started":"2024-11-14T19:49:35.349515Z","shell.execute_reply":"2024-11-14T19:49:35.357155Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#scheduler.py\n\nimport logging\nimport math\n\nfrom torch.optim.lr_scheduler import LambdaLR\n\nlogger = logging.getLogger(__name__)\n\nclass ConstantLRSchedule(LambdaLR):\n    \"\"\" Constant learning rate schedule.\n    \"\"\"\n    def __init__(self, optimizer, last_epoch=-1):\n        super(ConstantLRSchedule, self).__init__(optimizer, lambda _: 1.0, last_epoch=last_epoch)\n\n\nclass WarmupConstantSchedule(LambdaLR):\n    \"\"\" Linear warmup and then constant.\n        Linearly increases learning rate schedule from 0 to 1 over `warmup_steps` training steps.\n        Keeps learning rate schedule equal to 1. after warmup_steps.\n    \"\"\"\n    def __init__(self, optimizer, warmup_steps, last_epoch=-1):\n        self.warmup_steps = warmup_steps\n        super(WarmupConstantSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n\n    def lr_lambda(self, step):\n        if step < self.warmup_steps:\n            return float(step) / float(max(1.0, self.warmup_steps))\n        return 1.\n\n\nclass WarmupLinearSchedule(LambdaLR):\n    \"\"\" Linear warmup and then linear decay.\n        Linearly increases learning rate from 0 to 1 over `warmup_steps` training steps.\n        Linearly decreases learning rate from 1. to 0. over remaining `t_total - warmup_steps` steps.\n    \"\"\"\n    def __init__(self, optimizer, warmup_steps, t_total, last_epoch=-1):\n        self.warmup_steps = warmup_steps\n        self.t_total = t_total\n        super(WarmupLinearSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n\n    def lr_lambda(self, step):\n        if step < self.warmup_steps:\n            return float(step) / float(max(1, self.warmup_steps))\n        return max(0.0, float(self.t_total - step) / float(max(1.0, self.t_total - self.warmup_steps)))\n\n\nclass WarmupCosineSchedule(LambdaLR):\n    \"\"\" Linear warmup and then cosine decay.\n        Linearly increases learning rate from 0 to 1 over `warmup_steps` training steps.\n        Decreases learning rate from 1. to 0. over remaining `t_total - warmup_steps` steps following a cosine curve.\n        If `cycles` (default=0.5) is different from default, learning rate follows cosine function after warmup.\n    \"\"\"\n    def __init__(self, optimizer, warmup_steps, t_total, cycles=.5, last_epoch=-1):\n        self.warmup_steps = warmup_steps\n        self.t_total = t_total\n        self.cycles = cycles\n        super(WarmupCosineSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n\n    def lr_lambda(self, step):\n        if step < self.warmup_steps:\n            return float(step) / float(max(1.0, self.warmup_steps))\n        # progress after warmup\n        progress = float(step - self.warmup_steps) / float(max(1, self.t_total - self.warmup_steps))\n        return max(0.0, 0.5 * (1. + math.cos(math.pi * float(self.cycles) * 2.0 * progress)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T19:49:35.359823Z","iopub.execute_input":"2024-11-14T19:49:35.360507Z","iopub.status.idle":"2024-11-14T19:49:35.400159Z","shell.execute_reply.started":"2024-11-14T19:49:35.360464Z","shell.execute_reply":"2024-11-14T19:49:35.399175Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#modeling.py\n\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport copy\nimport logging\nimport math\n\nfrom os.path import join as pjoin\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\n\nfrom torch.nn import CrossEntropyLoss, Dropout, Softmax, Linear, Conv2d, LayerNorm\n#from torch.nn.modules.utils import _pair\nfrom scipy import ndimage\n\n#import models.configs as configs\nlogger = logging.getLogger(__name__)\n\nATTENTION_Q = \"MultiHeadDotProductAttention_1/query\"\nATTENTION_K = \"MultiHeadDotProductAttention_1/key\"\nATTENTION_V = \"MultiHeadDotProductAttention_1/value\"\nATTENTION_OUT = \"MultiHeadDotProductAttention_1/out\"\nFC_0 = \"MlpBlock_3/Dense_0\"\nFC_1 = \"MlpBlock_3/Dense_1\"\nATTENTION_NORM = \"LayerNorm_0\"\nMLP_NORM = \"LayerNorm_2\"\n\n\ndef np2th(weights, conv=False):\n    \"\"\"Possibly convert HWIO to OIHW.\"\"\"\n    if conv:\n        weights = weights.transpose([3, 2, 0, 1])\n    return torch.from_numpy(weights)\n\n\ndef swish(x):\n    return x * torch.sigmoid(x)\n\n\nACT2FN = {\"gelu\": torch.nn.functional.gelu, \"relu\": torch.nn.functional.relu, \"swish\": swish}\n\n\nclass Attention(nn.Module):\n    def __init__(self, config, vis):\n        super(Attention, self).__init__()\n        self.vis = vis\n        self.num_attention_heads = config.transformer[\"num_heads\"]\n        self.attention_head_size = int(config.hidden_size / self.num_attention_heads)\n        self.all_head_size = self.num_attention_heads * self.attention_head_size\n\n        self.query = Linear(config.hidden_size, self.all_head_size)\n        self.key = Linear(config.hidden_size, self.all_head_size)\n        self.value = Linear(config.hidden_size, self.all_head_size)\n\n        self.out = Linear(config.hidden_size, config.hidden_size)\n        self.attn_dropout = Dropout(config.transformer[\"attention_dropout_rate\"])\n        self.proj_dropout = Dropout(config.transformer[\"attention_dropout_rate\"])\n\n        self.softmax = Softmax(dim=-1)\n\n    def transpose_for_scores(self, x):\n        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n        x = x.view(*new_x_shape)\n        return x.permute(0, 2, 1, 3)\n\n    def forward(self, hidden_states):\n        mixed_query_layer = self.query(hidden_states)\n        mixed_key_layer = self.key(hidden_states)\n        mixed_value_layer = self.value(hidden_states)\n\n        query_layer = self.transpose_for_scores(mixed_query_layer)\n        key_layer = self.transpose_for_scores(mixed_key_layer)\n        value_layer = self.transpose_for_scores(mixed_value_layer)\n\n        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n        attention_probs = self.softmax(attention_scores)\n        weights = attention_probs if self.vis else None\n        attention_probs = self.attn_dropout(attention_probs)\n\n        context_layer = torch.matmul(attention_probs, value_layer)\n        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n        context_layer = context_layer.view(*new_context_layer_shape)\n        attention_output = self.out(context_layer)\n        attention_output = self.proj_dropout(attention_output)\n        return attention_output, weights\n\n\nclass Mlp(nn.Module):\n    def __init__(self, config):\n        super(Mlp, self).__init__()\n        self.fc1 = Linear(config.hidden_size, config.transformer[\"mlp_dim\"])\n        self.fc2 = Linear(config.transformer[\"mlp_dim\"], config.hidden_size)\n        self.act_fn = ACT2FN[\"gelu\"]\n        self.dropout = Dropout(config.transformer[\"dropout_rate\"])\n\n        self._init_weights()\n\n    def _init_weights(self):\n        nn.init.xavier_uniform_(self.fc1.weight)\n        nn.init.xavier_uniform_(self.fc2.weight)\n        nn.init.normal_(self.fc1.bias, std=1e-6)\n        nn.init.normal_(self.fc2.bias, std=1e-6)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act_fn(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.dropout(x)\n        return x\n\n\nclass Embeddings(nn.Module):\n    \"\"\"Construct the embeddings from patch, position embeddings.\n    \"\"\"\n    def __init__(self, config, img_size, in_channels=3):\n        super(Embeddings, self).__init__()\n        self.hybrid = None\n        img_size = _pair(img_size)\n\n        if config.patches.get(\"grid\") is not None:\n            grid_size = config.patches[\"grid\"]\n            patch_size = (img_size[0] // 16 // grid_size[0], img_size[1] // 16 // grid_size[1])\n            n_patches = (img_size[0] // 16) * (img_size[1] // 16)\n            self.hybrid = True\n        else:\n            patch_size = _pair(config.patches[\"size\"])\n            n_patches = (img_size[0] // patch_size[0]) * (img_size[1] // patch_size[1])\n            self.hybrid = False\n\n        if self.hybrid:\n            self.hybrid_model = ResNetV2(block_units=config.resnet.num_layers,\n                                         width_factor=config.resnet.width_factor)\n            in_channels = self.hybrid_model.width * 16\n        self.patch_embeddings = Conv2d(in_channels=in_channels,\n                                       out_channels=config.hidden_size,\n                                       kernel_size=patch_size,\n                                       stride=patch_size)\n        self.position_embeddings = nn.Parameter(torch.zeros(1, n_patches+1, config.hidden_size))\n        self.cls_token = nn.Parameter(torch.zeros(1, 1, config.hidden_size))\n\n        self.dropout = Dropout(config.transformer[\"dropout_rate\"])\n\n    def forward(self, x):\n        B = x.shape[0]\n        cls_tokens = self.cls_token.expand(B, -1, -1)\n\n        if self.hybrid:\n            x = self.hybrid_model(x)\n        x = self.patch_embeddings(x)\n        x = x.flatten(2)\n        x = x.transpose(-1, -2)\n        x = torch.cat((cls_tokens, x), dim=1)\n\n        embeddings = x + self.position_embeddings\n        embeddings = self.dropout(embeddings)\n        return embeddings\n\n\nclass Block(nn.Module):\n    def __init__(self, config, vis):\n        super(Block, self).__init__()\n        self.hidden_size = config.hidden_size\n        self.attention_norm = LayerNorm(config.hidden_size, eps=1e-6)\n        self.ffn_norm = LayerNorm(config.hidden_size, eps=1e-6)\n        self.ffn = Mlp(config)\n        self.attn = Attention(config, vis)\n\n    def forward(self, x):\n        h = x\n        x = self.attention_norm(x)\n        x, weights = self.attn(x)\n        x = x + h\n\n        h = x\n        x = self.ffn_norm(x)\n        x = self.ffn(x)\n        x = x + h\n        return x, weights\n\n    def load_from(self, weights, n_block):\n        ROOT = f\"Transformer/encoderblock_{n_block}\"\n        with torch.no_grad():\n            query_weight = np2th(weights[pjoin(ROOT, ATTENTION_Q, \"kernel\")]).view(self.hidden_size, self.hidden_size).t()\n            key_weight = np2th(weights[pjoin(ROOT, ATTENTION_K, \"kernel\")]).view(self.hidden_size, self.hidden_size).t()\n            value_weight = np2th(weights[pjoin(ROOT, ATTENTION_V, \"kernel\")]).view(self.hidden_size, self.hidden_size).t()\n            out_weight = np2th(weights[pjoin(ROOT, ATTENTION_OUT, \"kernel\")]).view(self.hidden_size, self.hidden_size).t()\n\n            query_bias = np2th(weights[pjoin(ROOT, ATTENTION_Q, \"bias\")]).view(-1)\n            key_bias = np2th(weights[pjoin(ROOT, ATTENTION_K, \"bias\")]).view(-1)\n            value_bias = np2th(weights[pjoin(ROOT, ATTENTION_V, \"bias\")]).view(-1)\n            out_bias = np2th(weights[pjoin(ROOT, ATTENTION_OUT, \"bias\")]).view(-1)\n\n            self.attn.query.weight.copy_(query_weight)\n            self.attn.key.weight.copy_(key_weight)\n            self.attn.value.weight.copy_(value_weight)\n            self.attn.out.weight.copy_(out_weight)\n            self.attn.query.bias.copy_(query_bias)\n            self.attn.key.bias.copy_(key_bias)\n            self.attn.value.bias.copy_(value_bias)\n            self.attn.out.bias.copy_(out_bias)\n\n            mlp_weight_0 = np2th(weights[pjoin(ROOT, FC_0, \"kernel\")]).t()\n            mlp_weight_1 = np2th(weights[pjoin(ROOT, FC_1, \"kernel\")]).t()\n            mlp_bias_0 = np2th(weights[pjoin(ROOT, FC_0, \"bias\")]).t()\n            mlp_bias_1 = np2th(weights[pjoin(ROOT, FC_1, \"bias\")]).t()\n\n            self.ffn.fc1.weight.copy_(mlp_weight_0)\n            self.ffn.fc2.weight.copy_(mlp_weight_1)\n            self.ffn.fc1.bias.copy_(mlp_bias_0)\n            self.ffn.fc2.bias.copy_(mlp_bias_1)\n\n            self.attention_norm.weight.copy_(np2th(weights[pjoin(ROOT, ATTENTION_NORM, \"scale\")]))\n            self.attention_norm.bias.copy_(np2th(weights[pjoin(ROOT, ATTENTION_NORM, \"bias\")]))\n            self.ffn_norm.weight.copy_(np2th(weights[pjoin(ROOT, MLP_NORM, \"scale\")]))\n            self.ffn_norm.bias.copy_(np2th(weights[pjoin(ROOT, MLP_NORM, \"bias\")]))\n\n\nclass Encoder(nn.Module):\n    def __init__(self, config, vis):\n        super(Encoder, self).__init__()\n        self.vis = vis\n        self.layer = nn.ModuleList()\n        self.encoder_norm = LayerNorm(config.hidden_size, eps=1e-6)\n        for _ in range(config.transformer[\"num_layers\"]):\n            layer = Block(config, vis)\n            self.layer.append(copy.deepcopy(layer))\n\n    def forward(self, hidden_states):\n        attn_weights = []\n        for layer_block in self.layer:\n            hidden_states, weights = layer_block(hidden_states)\n            if self.vis:\n                attn_weights.append(weights)\n        encoded = self.encoder_norm(hidden_states)\n        return encoded, attn_weights\n\n\nclass Transformer(nn.Module):\n    def __init__(self, config, img_size, vis):\n        super(Transformer, self).__init__()\n        self.embeddings = Embeddings(config, img_size=img_size)\n        self.encoder = Encoder(config, vis)\n\n    def forward(self, input_ids):\n        embedding_output = self.embeddings(input_ids)\n        encoded, attn_weights = self.encoder(embedding_output)\n        return encoded, attn_weights\n\n\nclass VisionTransformer(nn.Module):\n    def __init__(self, config, img_size=224, num_classes=21843, zero_head=False, vis=False):\n        super(VisionTransformer, self).__init__()\n        self.num_classes = num_classes\n        self.zero_head = zero_head\n        self.classifier = config.classifier\n        self.configg = config\n        self.transformer = Transformer(config, img_size, vis)\n        self.head = Linear(config.hidden_size, num_classes)\n\n    def forward(self, x, labels=None):\n        #print(x.size())\n        x, attn_weights = self.transformer(x)\n        logits = self.head(x[:, 0])\n        #print(self.configg)\n        if labels is not None:\n            loss_fct = CrossEntropyLoss()\n            loss = loss_fct(logits.view(-1, self.num_classes), labels.view(-1))\n            return loss\n        else:\n            return logits, attn_weights\n\n    def load_from(self, weights):\n        with torch.no_grad():\n            if self.zero_head:\n                nn.init.zeros_(self.head.weight)\n                nn.init.zeros_(self.head.bias)\n            else:\n                self.head.weight.copy_(np2th(weights[\"head/kernel\"]).t())\n                self.head.bias.copy_(np2th(weights[\"head/bias\"]).t())\n\n            self.transformer.embeddings.patch_embeddings.weight.copy_(np2th(weights[\"embedding/kernel\"], conv=True))\n            self.transformer.embeddings.patch_embeddings.bias.copy_(np2th(weights[\"embedding/bias\"]))\n            self.transformer.embeddings.cls_token.copy_(np2th(weights[\"cls\"]))\n            self.transformer.encoder.encoder_norm.weight.copy_(np2th(weights[\"Transformer/encoder_norm/scale\"]))\n            self.transformer.encoder.encoder_norm.bias.copy_(np2th(weights[\"Transformer/encoder_norm/bias\"]))\n\n            posemb = np2th(weights[\"Transformer/posembed_input/pos_embedding\"])\n            posemb_new = self.transformer.embeddings.position_embeddings\n            if posemb.size() == posemb_new.size():\n                self.transformer.embeddings.position_embeddings.copy_(posemb)\n            else:\n                logger.info(\"load_pretrained: resized variant: %s to %s\" % (posemb.size(), posemb_new.size()))\n                ntok_new = posemb_new.size(1)\n\n                if self.classifier == \"token\":\n                    posemb_tok, posemb_grid = posemb[:, :1], posemb[0, 1:]\n                    ntok_new -= 1\n                else:\n                    posemb_tok, posemb_grid = posemb[:, :0], posemb[0]\n\n                gs_old = int(np.sqrt(len(posemb_grid)))\n                gs_new = int(np.sqrt(ntok_new))\n                print('load_pretrained: grid-size from %s to %s' % (gs_old, gs_new))\n                posemb_grid = posemb_grid.reshape(gs_old, gs_old, -1)\n\n                zoom = (gs_new / gs_old, gs_new / gs_old, 1)\n                posemb_grid = ndimage.zoom(posemb_grid, zoom, order=1)\n                posemb_grid = posemb_grid.reshape(1, gs_new * gs_new, -1)\n                posemb = np.concatenate([posemb_tok, posemb_grid], axis=1)\n                self.transformer.embeddings.position_embeddings.copy_(np2th(posemb))\n\n            for bname, block in self.transformer.encoder.named_children():\n                for uname, unit in block.named_children():\n                    unit.load_from(weights, n_block=uname)\n\n            if self.transformer.embeddings.hybrid:\n                self.transformer.embeddings.hybrid_model.root.conv.weight.copy_(np2th(weights[\"conv_root/kernel\"], conv=True))\n                gn_weight = np2th(weights[\"gn_root/scale\"]).view(-1)\n                gn_bias = np2th(weights[\"gn_root/bias\"]).view(-1)\n                self.transformer.embeddings.hybrid_model.root.gn.weight.copy_(gn_weight)\n                self.transformer.embeddings.hybrid_model.root.gn.bias.copy_(gn_bias)\n\n                for bname, block in self.transformer.embeddings.hybrid_model.body.named_children():\n                    for uname, unit in block.named_children():\n                        unit.load_from(weights, n_block=bname, n_unit=uname)\n\n\nCONFIGS = {\n    'ViT-B_16': get_b16_config(),\n    'testing': get_testing(),\n}\n'''\n'ViT-B_32': get_b32_config(),\n    'ViT-L_16': get_l16_config(),\n    'ViT-L_32': get_l32_config(),\n    'ViT-H_14': get_h14_config(),\n    'R50-ViT-B_16': get_r50_b16_config(),\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T19:51:16.030155Z","iopub.execute_input":"2024-11-14T19:51:16.030608Z","iopub.status.idle":"2024-11-14T19:51:16.118646Z","shell.execute_reply.started":"2024-11-14T19:51:16.030566Z","shell.execute_reply":"2024-11-14T19:51:16.117706Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"\"\\n'ViT-B_32': get_b32_config(),\\n    'ViT-L_16': get_l16_config(),\\n    'ViT-L_32': get_l32_config(),\\n    'ViT-H_14': get_h14_config(),\\n    'R50-ViT-B_16': get_r50_b16_config(),\\n\""},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"#rearrange.py\n\n\n# pytorch imports\nimport torch\nimport torchvision\nfrom torchvision import models, transforms, datasets\nfrom torch.utils.data import DataLoader\nfrom torch import nn\nfrom torch import optim\nfrom torch.autograd import Variable\n\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\nimport collections\nfrom shutil import copy\nfrom shutil import copytree, rmtree\nimport random\nfrom tqdm import tqdm_notebook as tqdm\nimport math\nimport time\n# Helper method to split dataset into train and test folders\ndef prepare_data(filepath, src, dest):\n    classes_images = defaultdict(list)\n    with open(filepath, 'r') as txt:\n        paths = [read.strip() for read in txt.readlines()]\n        for p in paths:\n            food = p.split('/')\n            classes_images[food[0]].append(food[1] + '.jpg')\n\n    for food in classes_images.keys():\n        print(\"\\nCopying images into \",food)\n        if not os.path.exists(os.path.join(dest,food)):\n            os.makedirs(os.path.join(dest,food))\n        for i in classes_images[food]:\n            copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n    print(\"Copying Done!\")\n\n# # Prepare train dataset by copying images from food-101/images to food-101/train using the file train.txt\n\"\"\"\nprint(\"Creating train data...\")\nMETA_PATH = dataset_path+\"/food-101/meta/\"\nIMG_PATH = dataset_path+\"/food-101/images/\"\nTRAIN_PATH = dataset_path+\"/food-101-processed/train/\"\nprepare_data(META_PATH+'train.txt', IMG_PATH, TRAIN_PATH)\n\"\"\"\n\n# # Prepare validation data by copying images from food-101/images to food-101/valid using the file test.txt\n\"\"\"\nprint(\"Creating validation data...\")\nMETA_PATH = dataset_path+\"/food-101/meta/\"\nIMG_PATH = dataset_path+\"/food-101/images/\"\nTEST_PATH = dataset_path+\"/food-101-processed/test/\"\nprepare_data(META_PATH+'test.txt', IMG_PATH, TEST_PATH)\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T19:51:16.120481Z","iopub.execute_input":"2024-11-14T19:51:16.120895Z","iopub.status.idle":"2024-11-14T19:51:16.135609Z","shell.execute_reply.started":"2024-11-14T19:51:16.120847Z","shell.execute_reply":"2024-11-14T19:51:16.134721Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'\\nprint(\"Creating validation data...\")\\nMETA_PATH = dataset_path+\"/food-101/meta/\"\\nIMG_PATH = dataset_path+\"/food-101/images/\"\\nTEST_PATH = dataset_path+\"/food-101-processed/test/\"\\nprepare_data(META_PATH+\\'test.txt\\', IMG_PATH, TEST_PATH)\\n'"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"pip install --upgrade pyramid\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:20:20.347851Z","iopub.execute_input":"2024-11-14T20:20:20.348851Z","iopub.status.idle":"2024-11-14T20:20:35.088593Z","shell.execute_reply.started":"2024-11-14T20:20:20.348786Z","shell.execute_reply":"2024-11-14T20:20:35.087410Z"}},"outputs":[{"name":"stdout","text":"Collecting pyramid\n  Downloading pyramid-2.0.2-py3-none-any.whl.metadata (20 kB)\nCollecting hupper>=1.5 (from pyramid)\n  Downloading hupper-1.12.1-py3-none-any.whl.metadata (3.7 kB)\nCollecting plaster (from pyramid)\n  Downloading plaster-1.1.2-py2.py3-none-any.whl.metadata (6.4 kB)\nCollecting plaster-pastedeploy (from pyramid)\n  Downloading plaster_pastedeploy-1.0.1-py2.py3-none-any.whl.metadata (8.1 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pyramid) (70.0.0)\nCollecting translationstring>=0.4 (from pyramid)\n  Downloading translationstring-1.4-py2.py3-none-any.whl.metadata (4.1 kB)\nCollecting venusian>=1.0 (from pyramid)\n  Downloading venusian-3.1.0-py3-none-any.whl.metadata (10 kB)\nCollecting webob>=1.8.3 (from pyramid)\n  Downloading WebOb-1.8.9-py2.py3-none-any.whl.metadata (11 kB)\nCollecting zope.deprecation>=3.5.0 (from pyramid)\n  Downloading zope.deprecation-5.0-py3-none-any.whl.metadata (5.1 kB)\nCollecting zope.interface>=3.8.0 (from pyramid)\n  Downloading zope.interface-7.1.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting PasteDeploy>=2.0 (from plaster-pastedeploy->pyramid)\n  Downloading PasteDeploy-3.1.0-py3-none-any.whl.metadata (2.7 kB)\nDownloading pyramid-2.0.2-py3-none-any.whl (247 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hupper-1.12.1-py3-none-any.whl (22 kB)\nDownloading translationstring-1.4-py2.py3-none-any.whl (15 kB)\nDownloading venusian-3.1.0-py3-none-any.whl (13 kB)\nDownloading WebOb-1.8.9-py2.py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.4/115.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading zope.deprecation-5.0-py3-none-any.whl (10 kB)\nDownloading zope.interface-7.1.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (254 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.2/254.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading plaster-1.1.2-py2.py3-none-any.whl (11 kB)\nDownloading plaster_pastedeploy-1.0.1-py2.py3-none-any.whl (7.8 kB)\nDownloading PasteDeploy-3.1.0-py3-none-any.whl (16 kB)\nInstalling collected packages: translationstring, zope.interface, zope.deprecation, webob, venusian, plaster, PasteDeploy, hupper, plaster-pastedeploy, pyramid\nSuccessfully installed PasteDeploy-3.1.0 hupper-1.12.1 plaster-1.1.2 plaster-pastedeploy-1.0.1 pyramid-2.0.2 translationstring-1.4 venusian-3.1.0 webob-1.8.9 zope.deprecation-5.0 zope.interface-7.1.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install apex","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:23:41.688765Z","iopub.execute_input":"2024-11-14T20:23:41.689750Z","iopub.status.idle":"2024-11-14T20:24:21.578156Z","shell.execute_reply.started":"2024-11-14T20:23:41.689696Z","shell.execute_reply":"2024-11-14T20:24:21.576985Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting apex\n  Downloading apex-0.9.10dev.tar.gz (36 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting cryptacular (from apex)\n  Downloading cryptacular-1.6.2.tar.gz (75 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.8/75.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting zope.sqlalchemy (from apex)\n  Downloading zope.sqlalchemy-3.1-py3-none-any.whl.metadata (18 kB)\nCollecting velruse>=1.0.3 (from apex)\n  Downloading velruse-1.1.1.tar.gz (709 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.8/709.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pyramid>1.1.2 in /opt/conda/lib/python3.10/site-packages (from apex) (2.0.2)\nCollecting pyramid_mailer (from apex)\n  Downloading pyramid_mailer-0.15.1-py2.py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from apex) (2.32.3)\nCollecting wtforms (from apex)\n  Downloading wtforms-3.2.1-py3-none-any.whl.metadata (5.3 kB)\nCollecting wtforms-recaptcha (from apex)\n  Downloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl.metadata (3.1 kB)\nRequirement already satisfied: hupper>=1.5 in /opt/conda/lib/python3.10/site-packages (from pyramid>1.1.2->apex) (1.12.1)\nRequirement already satisfied: plaster in /opt/conda/lib/python3.10/site-packages (from pyramid>1.1.2->apex) (1.1.2)\nRequirement already satisfied: plaster-pastedeploy in /opt/conda/lib/python3.10/site-packages (from pyramid>1.1.2->apex) (1.0.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pyramid>1.1.2->apex) (70.0.0)\nRequirement already satisfied: translationstring>=0.4 in /opt/conda/lib/python3.10/site-packages (from pyramid>1.1.2->apex) (1.4)\nRequirement already satisfied: venusian>=1.0 in /opt/conda/lib/python3.10/site-packages (from pyramid>1.1.2->apex) (3.1.0)\nRequirement already satisfied: webob>=1.8.3 in /opt/conda/lib/python3.10/site-packages (from pyramid>1.1.2->apex) (1.8.9)\nRequirement already satisfied: zope.deprecation>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from pyramid>1.1.2->apex) (5.0)\nRequirement already satisfied: zope.interface>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from pyramid>1.1.2->apex) (7.1.1)\nRequirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from velruse>=1.0.3->apex) (2.0.0)\nCollecting anykeystore (from velruse>=1.0.3->apex)\n  Downloading anykeystore-0.2.tar.gz (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting python3-openid (from velruse>=1.0.3->apex)\n  Downloading python3_openid-3.2.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting pbkdf2 (from cryptacular->apex)\n  Downloading pbkdf2-1.3.tar.gz (6.4 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting repoze.sendmail>=4.1 (from pyramid_mailer->apex)\n  Downloading repoze.sendmail-4.4.1-py2.py3-none-any.whl.metadata (8.3 kB)\nCollecting transaction (from pyramid_mailer->apex)\n  Downloading transaction-5.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->apex) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->apex) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->apex) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->apex) (2024.8.30)\nRequirement already satisfied: markupsafe in /opt/conda/lib/python3.10/site-packages (from wtforms->apex) (2.1.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from zope.sqlalchemy->apex) (21.3)\nRequirement already satisfied: SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1 in /opt/conda/lib/python3.10/site-packages (from zope.sqlalchemy->apex) (2.0.30)\nRequirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1->zope.sqlalchemy->apex) (4.12.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1->zope.sqlalchemy->apex) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->zope.sqlalchemy->apex) (3.1.2)\nRequirement already satisfied: PasteDeploy>=2.0 in /opt/conda/lib/python3.10/site-packages (from plaster-pastedeploy->pyramid>1.1.2->apex) (3.1.0)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from python3-openid->velruse>=1.0.3->apex) (0.7.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib->velruse>=1.0.3->apex) (3.2.2)\nDownloading pyramid_mailer-0.15.1-py2.py3-none-any.whl (19 kB)\nDownloading wtforms-3.2.1-py3-none-any.whl (152 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.5/152.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl (7.5 kB)\nDownloading zope.sqlalchemy-3.1-py3-none-any.whl (23 kB)\nDownloading repoze.sendmail-4.4.1-py2.py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transaction-5.0-py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python3_openid-3.2.0-py3-none-any.whl (133 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: apex, velruse, cryptacular, anykeystore, pbkdf2\n  Building wheel for apex (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for apex: filename=apex-0.9.10.dev0-py3-none-any.whl size=46442 sha256=0c47f8e6d6202698d3fd9795ea30996447f667cbebf1b28c26563b179c4609cc\n  Stored in directory: /root/.cache/pip/wheels/6e/62/59/9b100fce7ebd989603b3b7a4ca259150da72c9e107fcaa2a30\n  Building wheel for velruse (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for velruse: filename=velruse-1.1.1-py3-none-any.whl size=50909 sha256=07eeb7299c435126cfd0deb2868aedb86ac722dcd53a8b9f90f9818bf470e8fb\n  Stored in directory: /root/.cache/pip/wheels/4a/f9/a4/fc4ea7b935ee9c58b9bc772cabd94f6a8560f35444097d948d\n  Building wheel for cryptacular (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for cryptacular: filename=cryptacular-1.6.2-cp310-cp310-linux_x86_64.whl size=28076 sha256=2c285e232e4247e6b282472b0c5920b92fe862b9534ffb72f26af41a392347f2\n  Stored in directory: /root/.cache/pip/wheels/3f/6e/09/a7fba517f95b2a6a36bd01b6d4f4679fa7259615a493b64b8f\n  Building wheel for anykeystore (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for anykeystore: filename=anykeystore-0.2-py3-none-any.whl size=16813 sha256=522d8ef946d653de0f2f6f1275dbabaacfcd8ba9d24370f67fe4bb85dcf5ea99\n  Stored in directory: /root/.cache/pip/wheels/ce/9e/24/35542b7d376b53a6f8426524cc5a3f7998f975037b32d19906\n  Building wheel for pbkdf2 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pbkdf2: filename=pbkdf2-1.3-py3-none-any.whl size=5083 sha256=36f4f0e5a20c53cea4d6904ed0bffcab8f23d2695214d1f833b33db33c2b713f\n  Stored in directory: /root/.cache/pip/wheels/f6/7d/8b/4269ff90fda80497ec59f6ff7d1e1596cb697c1dc8e9bbe320\nSuccessfully built apex velruse cryptacular anykeystore pbkdf2\nInstalling collected packages: pbkdf2, anykeystore, wtforms, python3-openid, cryptacular, wtforms-recaptcha, transaction, zope.sqlalchemy, velruse, repoze.sendmail, pyramid_mailer, apex\nSuccessfully installed anykeystore-0.2 apex-0.9.10.dev0 cryptacular-1.6.2 pbkdf2-1.3 pyramid_mailer-0.15.1 python3-openid-3.2.0 repoze.sendmail-4.4.1 transaction-5.0 velruse-1.1.1 wtforms-3.2.1 wtforms-recaptcha-0.3.2 zope.sqlalchemy-3.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#train.py\n\nfrom __future__ import absolute_import, division, print_function\n\nimport logging\nimport argparse\nimport os\nimport random\nimport numpy as np\n\nfrom datetime import timedelta\n\nimport torch\nimport torch.distributed as dist\n\nfrom tqdm import tqdm\nfrom torch.utils.tensorboard import SummaryWriter\nfrom apex import amp\nfrom apex.parallel import DistributedDataParallel as DDP\nfrom utils.scheduler import WarmupLinearSchedule, WarmupCosineSchedule\nfrom utils.data_utils import get_loader\nfrom utils.dist_util import get_world_size\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef simple_accuracy(preds, labels):\n    return (preds == labels).mean()\n\n\ndef save_model(args, model):\n    model_to_save = model.module if hasattr(model, 'module') else model\n    model_checkpoint = os.path.join(args.output_dir, \"%s_checkpoint.bin\" % args.name)\n    torch.save(model_to_save.state_dict(), model_checkpoint)\n    logger.info(\"Saved model checkpoint to [DIR: %s]\", args.output_dir)\n\n\ndef setup(args):\n    # Prepare model\n    config = CONFIGS[args.model_type]\n\n    num_classes = 101 if args.dataset == \"cifar10\" else 100\n\n    model = VisionTransformer(config, args.img_size, zero_head=True, num_classes=num_classes)\n    model.load_from(np.load(args.pretrained_dir))\n    model.to(args.device)\n    num_params = count_parameters(model)\n\n    logger.info(\"{}\".format(config))\n    logger.info(\"Training parameters %s\", args)\n    logger.info(\"Total Parameter: \\t%2.1fM\" % num_params)\n    print(num_params)\n    return args, model\n\n\ndef count_parameters(model):\n    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    return params/1000000\n\n\ndef set_seed(args):\n    random.seed(args.seed)\n    np.random.seed(args.seed)\n    torch.manual_seed(args.seed)\n    if args.n_gpu > 0:\n        torch.cuda.manual_seed_all(args.seed)\n\n\ndef valid(args, model, writer, test_loader, global_step):\n    # Validation!\n    eval_losses = AverageMeter()\n\n    logger.info(\"***** Running Validation *****\")\n    logger.info(\"  Num steps = %d\", len(test_loader))\n    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n\n    model.eval()\n    all_preds, all_label = [], []\n    epoch_iterator = tqdm(test_loader,\n                          desc=\"Validating... (loss=X.X)\",\n                          bar_format=\"{l_bar}{r_bar}\",\n                          dynamic_ncols=True,\n                          disable=args.local_rank not in [-1, 0])\n    loss_fct = torch.nn.CrossEntropyLoss()\n    for step, batch in enumerate(epoch_iterator):\n        batch = tuple(t.to(args.device) for t in batch)\n        x, y = batch\n        with torch.no_grad():\n            logits = model(x)[0]\n            eval_loss = loss_fct(logits, y)\n            eval_losses.update(eval_loss.item())\n\n            preds = torch.argmax(logits, dim=-1)\n\n        if len(all_preds) == 0:\n            all_preds.append(preds.detach().cpu().numpy())\n            all_label.append(y.detach().cpu().numpy())\n        else:\n            all_preds[0] = np.append(\n                all_preds[0], preds.detach().cpu().numpy(), axis=0\n            )\n            all_label[0] = np.append(\n                all_label[0], y.detach().cpu().numpy(), axis=0\n            )\n        epoch_iterator.set_description(\"Validating... (loss=%2.5f)\" % eval_losses.val)\n\n    all_preds, all_label = all_preds[0], all_label[0]\n    accuracy = simple_accuracy(all_preds, all_label)\n\n    logger.info(\"\\n\")\n    logger.info(\"Validation Results\")\n    logger.info(\"Global Steps: %d\" % global_step)\n    logger.info(\"Valid Loss: %2.5f\" % eval_losses.avg)\n    logger.info(\"Valid Accuracy: %2.5f\" % accuracy)\n\n    writer.add_scalar(\"test/accuracy\", scalar_value=accuracy, global_step=global_step)\n    return accuracy\n\n\ndef train(args, model):\n    \"\"\" Train the model \"\"\"\n    if args.local_rank in [-1, 0]:\n        os.makedirs(args.output_dir, exist_ok=True)\n        writer = SummaryWriter(log_dir=os.path.join(\"logs\", args.name))\n    args.train_batch_size = args.train_batch_size // args.gradient_accumulation_steps\n    # Prepare dataset\n    train_loader, test_loader = get_loader(args)\n    # Prepare optimizer and scheduler\n    optimizer = torch.optim.SGD(model.parameters(),\n                                lr=args.learning_rate,\n                                momentum=0.9,\n                                weight_decay=args.weight_decay)\n    t_total = args.num_steps\n    if args.decay_type == \"cosine\":\n        scheduler = WarmupCosineSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total)\n    else:\n        scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total)\n\n    if args.fp16:\n        model, optimizer = amp.initialize(models=model,\n                                          optimizers=optimizer,\n                                          opt_level=args.fp16_opt_level)\n        amp._amp_state.loss_scalers[0]._loss_scale = 2**20\n\n    # Distributed training\n    if args.local_rank != -1:\n        model = DDP(model, message_size=250000000, gradient_predivide_factor=get_world_size())\n\n    # Train!\n    logger.info(\"***** Running training *****\")\n    logger.info(\"  Total optimization steps = %d\", args.num_steps)\n    logger.info(\"  Instantaneous batch size per GPU = %d\", args.train_batch_size)\n    logger.info(\"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n                args.train_batch_size * args.gradient_accumulation_steps * (\n                    torch.distributed.get_world_size() if args.local_rank != -1 else 1))\n    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n\n    model.zero_grad()\n    set_seed(args)  # Added here for reproducibility (even between python 2 and 3)\n    losses = AverageMeter()\n    global_step, best_acc = 0, 0\n    while True:\n        model.train()\n        epoch_iterator = tqdm(train_loader,\n                              desc=\"Training (X / X Steps) (loss=X.X)\",\n                              bar_format=\"{l_bar}{r_bar}\",\n                              dynamic_ncols=True,\n                              disable=args.local_rank not in [-1, 0])\n        for step, batch in enumerate(epoch_iterator):\n            batch = tuple(t.to(args.device) for t in batch)\n            x, y = batch\n            loss = model(x, y)\n\n            if args.gradient_accumulation_steps > 1:\n                loss = loss / args.gradient_accumulation_steps\n            if args.fp16:\n                with amp.scale_loss(loss, optimizer) as scaled_loss:\n                    scaled_loss.backward()\n            else:\n                loss.backward()\n\n            if (step + 1) % args.gradient_accumulation_steps == 0:\n                losses.update(loss.item()*args.gradient_accumulation_steps)\n                if args.fp16:\n                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n                else:\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n                scheduler.step()\n                optimizer.step()\n                optimizer.zero_grad()\n                global_step += 1\n                epoch_iterator.set_description(\n                    \"Training (%d / %d Steps) (loss=%2.5f)\" % (global_step, t_total, losses.val)\n                )\n                # load the best checkpoint if you want to perform only test\n                #model.load_state_dict(torch.load(\"best_checkpoint.bin\"))\n                if args.local_rank in [-1, 0]:\n                    writer.add_scalar(\"train/loss\", scalar_value=losses.val, global_step=global_step)\n                    writer.add_scalar(\"train/lr\", scalar_value=scheduler.get_lr()[0], global_step=global_step)\n                if global_step % args.eval_every == 0 and args.local_rank in [-1, 0]:\n                    accuracy = valid(args, model, writer, test_loader, global_step)\n                    if best_acc < accuracy:\n                        #save_model(args, model)\n                        #don't save any model at the time of only testing\n                        save_model(args, model)\n                        best_acc = accuracy\n                    model.train()\n\n                if global_step % t_total == 0:\n                    break\n        losses.reset()\n        if global_step % t_total == 0:\n            break\n\n    if args.local_rank in [-1, 0]:\n        writer.close()\n    logger.info(\"Best Accuracy: \\t%f\" % best_acc)\n    logger.info(\"End Training!\")\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    # Required parameters\n    parser.add_argument(\"--name\", required=False,\n                        help=\"Name of this run. Used for monitoring.\", default=\"best_checkpoint\")\n    parser.add_argument(\"--dataset\", choices=[\"cifar10\", \"cifar100\"], default=\"cifar10\",\n                        help=\"Which downstream task.\")\n    parser.add_argument(\"--dataset_path\", default=\"root-path/food-101-processed\",help=\"root dataset path\")\n    parser.add_argument(\"--model_type\", choices=[\"ViT-B_16\", \"ViT-B_32\", \"ViT-L_16\",\n                                                 \"ViT-L_32\", \"ViT-H_14\", \"R50-ViT-B_16\"],default=\"ViT-B_16\",\n                        help=\"Which variant to use.\")\n    parser.add_argument(\"--pretrained_dir\", type=str, default=\"pretrained-model-path/ViT-B_16.npz\",\n                        help=\"Where to search for pretrained ViT models.\")\n    parser.add_argument(\"--output_dir\", default=\"output-path/\", type=str,\n                        help=\"The output directory where checkpoints will be written.\")\n\n    parser.add_argument(\"--img_size\", default=224, type=int,\n                        help=\"Resolution size\")\n    parser.add_argument(\"--train_batch_size\", default=32, type=int,\n                        help=\"Total batch size for training.\")\n    parser.add_argument(\"--eval_batch_size\", default=32, type=int,\n                        help=\"Total batch size for eval.\")\n    parser.add_argument(\"--eval_every\", default=10000, type=int,\n                        help=\"Run prediction on validation set every so many steps.\"\n                             \"Will always run one evaluation at the end of training.\")\n\n    parser.add_argument(\"--learning_rate\", default=3e-2, type=float,\n                        help=\"The initial learning rate for SGD.\")\n    parser.add_argument(\"--weight_decay\", default=0, type=float,\n                        help=\"Weight deay if we apply some.\")\n    parser.add_argument(\"--num_steps\", default=100000, type=int,\n                        help=\"Total number of training epochs to perform.\")\n    parser.add_argument(\"--decay_type\", choices=[\"cosine\", \"linear\"], default=\"cosine\",\n                        help=\"How to decay the learning rate.\")\n    parser.add_argument(\"--warmup_steps\", default=500, type=int,\n                        help=\"Step of training to perform learning rate warmup for.\")\n    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float,\n                        help=\"Max gradient norm.\")\n\n    parser.add_argument(\"--local_rank\", type=int, default=-1,\n                        help=\"local_rank for distributed training on gpus\")\n    parser.add_argument('--seed', type=int, default=42,\n                        help=\"random seed for initialization\")\n    parser.add_argument('--gradient_accumulation_steps', type=int, default=1,\n                        help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n    parser.add_argument('--fp16', action='store_true',\n                        help=\"Whether to use 16-bit float precision instead of 32-bit\")\n    parser.add_argument('--fp16_opt_level', type=str, default='O2',\n                        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n                             \"See details at https://nvidia.github.io/apex/amp.html\")\n    parser.add_argument('--loss_scale', type=float, default=0,\n                        help=\"Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True.\\n\"\n                             \"0 (default value): dynamic loss scaling.\\n\"\n                             \"Positive power of 2: static loss scaling value.\\n\")\n    parser.add_argument(\"--phase\", choices=[\"train\", \"test\"], default=\"train\",help=\"Which operation you want to perform.\")\n    args = parser.parse_args()\n\n    # for multiple GPU we can directly assign the GPU index\n    if args.local_rank == -1:\n        device = 1\n        args.n_gpu = torch.cuda.device_count()\n    else:\n        torch.cuda.set_device(args.local_rank)\n        device = torch.device(\"cuda\", args.local_rank)\n        torch.distributed.init_process_group(backend='nccl',\n                                             timeout=timedelta(minutes=60))\n        args.n_gpu = 1\n    args.device = device\n\n    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n                        datefmt='%m/%d/%Y %H:%M:%S',\n                        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN)\n    logger.warning(\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\" %\n                   (args.local_rank, args.device, args.n_gpu, bool(args.local_rank != -1), args.fp16))\n    set_seed(args)\n    args, model = setup(args)\n    # Training\n    train(args, model)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:27:18.258750Z","iopub.execute_input":"2024-11-14T20:27:18.259127Z","iopub.status.idle":"2024-11-14T20:27:18.439989Z","shell.execute_reply.started":"2024-11-14T20:27:18.259090Z","shell.execute_reply":"2024-11-14T20:27:18.438607Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m amp\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapex\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedDataParallel \u001b[38;5;28;01mas\u001b[39;00m DDP\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscheduler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WarmupLinearSchedule, WarmupCosineSchedule\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/apex/__init__.py:13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyramid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterfaces\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (IAuthenticationPolicy,\n\u001b[1;32m     10\u001b[0m                                 IAuthorizationPolicy,\n\u001b[1;32m     11\u001b[0m                                 ISessionFactory)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyramid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msecurity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NO_PERMISSION_REQUIRED\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyramid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msession\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnencryptedCookieSessionFactoryConfig\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyramid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msettings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m asbool\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapex\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ApexAuthSecret,\n\u001b[1;32m     17\u001b[0m                              ApexSessionSecret)\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'UnencryptedCookieSessionFactoryConfig' from 'pyramid.session' (unknown location)"],"ename":"ImportError","evalue":"cannot import name 'UnencryptedCookieSessionFactoryConfig' from 'pyramid.session' (unknown location)","output_type":"error"}],"execution_count":5}]}